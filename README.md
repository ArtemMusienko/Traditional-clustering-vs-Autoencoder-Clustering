![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)![Google Colab](https://img.shields.io/badge/Google%20Colab-%23F9A825.svg?style=for-the-badge&logo=googlecolab&logoColor=white)![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white)![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white)![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white)![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white)

## Traditional clustering vs Autoencoder Clustering

Используемый [датасет](https://storage.yandexcloud.net/academy.ai/Mall_Customers.csv). Датасет загружен, проведено его исследование, удалены дубликаты, выполнено кодирование категориального признака, а также реализована предобработка данных.

---

**Traditional Clustering** – это совокупность классических алгоритмов машинного обучения без учителя, которые напрямую группируют исходные данные (или их линейные преобразования, такие как PCA) в кластеры на основе мер сходства или расстояния между точками. Эти методы, такие как K-means, DBSCAN или иерархическая кластеризация, стремятся максимизировать внутрикластерное сходство и минимизировать межкластерное, работая в пространстве исходных признаков. Они интерпретируемы, быстры и эффективны на данных малой и средней размерности с линейно разделимыми структурами, но их производительность резко падает на сложных, высокоразмерных или зашумленных данных, требующих тщательной предварительной обработки и feature engineering.

В **традиционном методе** кластеризации реализованы 3 метода для определения количества кластеров, а именно: **Метод Локтя**, **Silhouette Score** и **Gap Statistic**. В финальной части для визуализации используем `PCA`, он превращает сложные многомерные данные в простую двумерную картинку, сохраняя максимально возможную информацию о структуре данных.

---

**Autoencoder Clustering** – это современный гибридный подход, объединяющий глубокое обучение и кластеризацию, где сначала нейросетевой автоэнкодер (состоящий из энкодера и декодера) обучается реконструировать входные данные, извлекая при этом их низкоразмерные латентные представления, которые нелинейно выявляют наиболее существенные и сжатые признаки, игнорируя шумы. Затем, уже на этих компактных и семантически насыщенных латентных векторах, применяется традиционный алгоритм кластеризации (например, K-means). Этот метод особенно мощён для работы со сложными неструктурированными данными (изображения, текст, аудио), поскольку автоэнкодер автоматически выполняет нелинейное снижение размерности и выделение признаков, но он требует больших вычислительных ресурсов, сложен в настройке и менее интерпретируем по сравнению с классическими методами.

В **кластеризации с автокодировщиком** реализовано обучение модели, в основе которого лежат полносвязные слои (`Dense`). В финальной части визуализируем результаты кластеризации, в основе которых лежат скрытые представления.

---

Далее представлен вывод и сравнительный анализ двух методов, в результате которого победил метод кластеризации с автокодировщиком. 

> Использование графических ускорителей для запуска кода необязательно.
